{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/agnibrainhack/AmexModel/blob/master/AmEx.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('train.csv')\n",
    "dataset2 = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['product_category_2'] = dataset['product_category_2'].fillna(0)\n",
    "dataset['product_category_2']  = dataset['product_category_2'].apply(lambda x: '1' if x >0 else '0')\n",
    "\n",
    "dataset2['product_category_2'] = dataset2['product_category_2'].fillna(0)\n",
    "dataset2['product_category_2']  = dataset2['product_category_2'].apply(lambda x: '1' if x >0 else '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.dropna(how ='any',axis =0)\n",
    "\n",
    "dataset2 = dataset2.dropna(how ='any',axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['gender'] = dataset['gender'].map({'Female':0,'Male':1})\n",
    "\n",
    "dataset2['gender'] = dataset2['gender'].map({'Female':0,'Male':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(['session_id','user_depth'],axis =1)\n",
    "\n",
    "dataset = dataset.drop(['campaign_id'],axis =1)\n",
    "\n",
    "dataset2 = dataset2.drop(['session_id','user_depth'],axis =1)\n",
    "\n",
    "dataset2 = dataset2.drop(['campaign_id'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster(x):\n",
    "    if x <= 10800:\n",
    "        return 0\n",
    "    if x > 10800 and x <= 21600:\n",
    "        return 1\n",
    "    if x > 21600 and x <= 32400:\n",
    "        return 2\n",
    "    if x > 32400 and x <= 43200:\n",
    "        return 3\n",
    "    if x > 43200 and x <= 54000:\n",
    "        return 4\n",
    "    if x > 54000 and x <= 64800:\n",
    "        return 5\n",
    "    if x > 64800 and x <= 75600:\n",
    "        return 6\n",
    "    if x > 75600 and x <= 86400:\n",
    "        return 7\n",
    "    if x > 86400 and x <= 97200:\n",
    "        return 0\n",
    "    if x > 97200 and x <= 108000:\n",
    "        return 1\n",
    "    if x > 108000 and x <= 118800:\n",
    "        return 2\n",
    "    if x > 118800 and x <= 129600:\n",
    "        return 3\n",
    "    if x > 129600 and x <= 140400:\n",
    "        return 4\n",
    "    if x > 140400 and x <= 151200:\n",
    "        return 5\n",
    "    if x > 151200 and x <= 162000:\n",
    "        return 6\n",
    "    if x > 162000 and x <= 172800:\n",
    "        return 7\n",
    "    if x > 172800 and x <= 183600:\n",
    "        return 0\n",
    "    if x > 183600 and x <= 194400:\n",
    "        return 1\n",
    "    if x > 194400 and x <= 205200:\n",
    "        return 2\n",
    "    if x > 205200 and x <= 216000:\n",
    "        return 3\n",
    "    if x > 216000 and x <= 226800:\n",
    "        return 4\n",
    "    if x > 226800 and x <= 237600:\n",
    "        return 5\n",
    "    if x > 237600 and x <= 248400:\n",
    "        return 6\n",
    "    if x > 248400 and x <= 259200:\n",
    "        return 7\n",
    "    if x > 259200:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first one for test\n",
    "dataset2['DateTime'] = dataset2['DateTime'].map(lambda x: time.mktime(datetime.datetime.\n",
    "       strptime(x, \"%Y-%m-%d %H:%M\").timetuple())-1499452200).astype('int64')\n",
    "dataset2['DateTime'] = dataset2['DateTime'].apply(cluster)\n",
    "#second one for train\n",
    "dataset['DateTime'] = dataset['DateTime'].map(lambda x: time.mktime(datetime.datetime.\n",
    "       strptime(x, \"%d-%m-%Y %H:%M\").timetuple())-1498933800).astype('int64')\n",
    "#dataset2.head()\n",
    "dataset['DateTime'] = dataset['DateTime'].apply(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset2['age_level'].unique()\n",
    "# dataset2['webpage_id'].unique()\n",
    "# dataset2['product'].unique()\n",
    "# #dataset2['campaign_id'].unique()\n",
    "# dataset2['product_category_1'].unique()\n",
    "# dataset2['user_group_id'].unique()\n",
    "# dataset2['city_development_index'].unique()\n",
    "# dataset2['DateTime'].unique()\n",
    "\n",
    "# dataset['age_level'].unique()\n",
    "# dataset['webpage_id'].unique()\n",
    "# dataset['product'].unique()\n",
    "# #dataset['campaign_id'].unique()\n",
    "# dataset['product_category_1'].unique()\n",
    "# dataset['user_group_id'].unique()\n",
    "# dataset['city_development_index'].unique()\n",
    "# dataset['DateTime'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.get_dummies(dataset['age_level'])\n",
    "data.columns = ('al_0','al_1','al_2','al_3','al_4','al_5','al_6')\n",
    "dataset = dataset.drop('age_level',axis =1)\n",
    "dataset = dataset.join(data)\n",
    "\n",
    "\n",
    "data1 = pd.get_dummies(dataset2['age_level'])\n",
    "data1.columns = ('al_0','al_1','al_2','al_3','al_4','al_5','al_6')\n",
    "dataset2 = dataset2.drop('age_level',axis =1)\n",
    "dataset2 = dataset2.join(data1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webpage = pd.get_dummies(dataset['webpage_id'])\n",
    "webpage.columns = ('wp_0','wp_1','wp_2','wp_3','wp_4','wp_5','wp_6','wp_7','wp_8')\n",
    "dataset = dataset.drop('webpage_id',axis =1)\n",
    "dataset = dataset.join(webpage)\n",
    "\n",
    "webpage1 = pd.get_dummies(dataset2['webpage_id'])\n",
    "webpage1.columns = ('wp_0','wp_1','wp_2','wp_3','wp_4','wp_5','wp_6','wp_7','wp_8')\n",
    "dataset2 = dataset2.drop('webpage_id',axis =1)\n",
    "dataset2 = dataset2.join(webpage1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = pd.get_dummies(dataset['product'])\n",
    "product.columns=('p_1','p_2','p_3','p_4','p_5','p_6','p_7','p_8','p_9','p_10')\n",
    "dataset = dataset.drop('product',axis =1)\n",
    "dataset = dataset.join(product)\n",
    "\n",
    "\n",
    "product1 = pd.get_dummies(dataset2['product'])\n",
    "product1.columns=('p_1','p_2','p_3','p_4','p_5','p_6','p_7','p_8','p_9','p_10')\n",
    "dataset2 = dataset2.drop('product',axis =1)\n",
    "dataset2 = dataset2.join(product1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_cat = pd.get_dummies(dataset['product_category_1'])\n",
    "product_cat.columns =('pc_1','pc_2','pc_3','pc_4','pc_5')\n",
    "dataset = dataset.drop('product_category_1',axis =1)\n",
    "dataset = dataset.join(product_cat)\n",
    "\n",
    "product_cat1 = pd.get_dummies(dataset2['product_category_1'])\n",
    "product_cat1.columns =('pc_1','pc_2','pc_3','pc_4','pc_5')\n",
    "dataset2 = dataset2.drop('product_category_1',axis =1)\n",
    "dataset2 = dataset2.join(product_cat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = pd.get_dummies(dataset['user_group_id'])\n",
    "user.columns = ('u_1','u_2','u_3','u_4','u_5','u_6','u_7','u_8','u_9','u_10','u_11','u_12','u_13')\n",
    "dataset = dataset.drop('user_group_id',axis =1)\n",
    "dataset = dataset.join(user)\n",
    "\n",
    "user1 = pd.get_dummies(dataset2['user_group_id'])\n",
    "user1.columns = ('u_1','u_2','u_3','u_4','u_5','u_6','u_7','u_8','u_9','u_10','u_11','u_12','u_13')\n",
    "dataset2 = dataset.drop('user_group_id',axis =1)\n",
    "dataset2 = dataset.join(user1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citydev = pd.get_dummies(dataset['city_development_index'])\n",
    "citydev.columns = ('city_dev_1','city_dev_2','city_dev_3','city_dev_4')\n",
    "dataset = dataset.drop('city_development_index',axis=1)\n",
    "dataset = dataset.join(citydev)\n",
    "\n",
    "citydev1 = pd.get_dummies(dataset2['city_development_index'])\n",
    "citydev1.columns = ('city_dev_1','city_dev_2','city_dev_3','city_dev_4')\n",
    "dataset2 = dataset2.drop('city_development_index',axis=1)\n",
    "dataset2 = dataset2.join(citydev1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date1 = pd.get_dummies(dataset['DateTime'])\n",
    "date1.columns = ('date_0','date_1','date_2','date_3','date_4','date_5','date_6','date_7')\n",
    "dataset = dataset.drop('DateTime',axis=1)\n",
    "dataset = dataset.join(date1)\n",
    "\n",
    "date2 = pd.get_dummies(dataset2['DateTime'])\n",
    "date2.columns = ('date_0','date_1','date_2','date_3','date_4','date_5','date_6','date_7')\n",
    "dataset2 = dataset2.drop('DateTime',axis=1)\n",
    "dataset2 = dataset2.join(date2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = dataset.to_csv('modified_merge_train_v.1.csv',index = False)\n",
    "\n",
    "#data1 = dataset2.to_csv('modified_merge_test_v.1.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "L7eUsMZcLiXy",
    "outputId": "73b0410c-fdf1-4157-b664-2caa6a5687f1",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-acbdce96-92f4-4418-a9dc-60a9d68521a3\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-acbdce96-92f4-4418-a9dc-60a9d68521a3\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving final_train.zip to final_train.zip\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "4ZsLGKrKMXwb",
    "outputId": "88eac480-e4b0-406d-eb1f-10bdecca6b6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Name                                             Modified             Size\n",
      "final_train.csv                                2018-11-17 14:30:40     49636843\n",
      "Extracting all the files now...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    " \n",
    "# specifying the zip file name\n",
    "file_name = \"final_train.zip\"\n",
    " \n",
    "# opening the zip file in READ mode\n",
    "with ZipFile(file_name, 'r') as zip:\n",
    "    # printing all the contents of the zip file\n",
    "    zip.printdir()\n",
    " \n",
    "    # extracting all the files\n",
    "    print('Extracting all the files now...')\n",
    "    zip.extractall()\n",
    "    print('Done!')\n",
    "    zip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ttGio8zALy21"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Dropout, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger, Callback  #early stopping ta aktu pore implement korchi\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "ThVMjJdgOrzK",
    "outputId": "3e652b2a-9ab0-48ef-b856-04b6d3d8a685"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_train.csv  final_train.zip  sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XXa5nIv_uQ_y"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('final_train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oldnKgFHL2NX"
   },
   "outputs": [],
   "source": [
    "train_majority = train[train['is_click'] == 0]\n",
    "train_minority = train[train['is_click'] == 1]\n",
    "train_minority_upsampled = resample(train_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=50000,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    "train_majority_downsampled = resample(train_majority, \n",
    "                                 replace=False,     # sample without replacement\n",
    "                                 n_samples=50000,    # to match minority class\n",
    "                                 random_state=123) # reproducible results\n",
    "train = pd.concat([train_majority_downsampled, train_minority_upsampled])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train[['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']] = scaler.fit_transform(train[['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QCqMmit3uNfc"
   },
   "outputs": [],
   "source": [
    "X = train.drop(columns=['is_click'])\n",
    "Y = train[['is_click']]\n",
    "# X , Y = loadData()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2tP26eKdL5ko"
   },
   "outputs": [],
   "source": [
    "class roc_callback(Callback):\n",
    "    def __init__(self,training_data,validation_data):\n",
    "        self.x = training_data[0]\n",
    "        self.y = training_data[1]\n",
    "        self.x_val = validation_data[0]\n",
    "        self.y_val = validation_data[1]\n",
    "\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(self.x)\n",
    "        roc = roc_auc_score(self.y, y_pred)\n",
    "        y_pred_val = self.model.predict(self.x_val)\n",
    "        roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
    "        print('\\rroc-auc: %s - roc-auc_val: %s' % (str(round(roc,4)),str(round(roc_val,4))),end=100*' '+'\\n')\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W1rdD7xwL61O"
   },
   "outputs": [],
   "source": [
    "def base_model():\n",
    "        model = Sequential()\n",
    "        model.add(Dense(250, input_dim=X_train.shape[1],\n",
    "                        kernel_initializer=keras.initializers.he_normal(seed=None)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.3))\n",
    "        \n",
    "        model.add(Dense(125, kernel_initializer=keras.initializers.he_normal(seed=None)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.2))\n",
    "        \n",
    "        model.add(Dense(85, kernel_initializer=keras.initializers.he_normal(seed=None)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.2))\n",
    "        \n",
    "        model.add(Dense(35, kernel_initializer=keras.initializers.he_normal(seed=None)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.1))\n",
    "        \n",
    "        model.add(Dense(10, kernel_initializer=keras.initializers.he_normal(seed=None)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "#         model.add(Dropout(0.08))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        # Compile model\n",
    "        opt = keras.optimizers.adam(lr=0.01, decay=1e-7)\n",
    "        model.compile(optimizer=opt, metrics = ['accuracy'], loss='binary_crossentropy')\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 803
    },
    "colab_type": "code",
    "id": "fmNH_07xL_Nj",
    "outputId": "1f20fe11-0863-423d-f974-df98f771a5de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 250)               17500     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 250)               1000      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 125)               31375     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 125)               500       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 85)                10710     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 85)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 85)                340       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 85)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 35)                3010      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 35)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 35)                140       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 35)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                360       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 64,986\n",
      "Trainable params: 63,976\n",
      "Non-trainable params: 1,010\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = base_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2174
    },
    "colab_type": "code",
    "id": "m2l9amICMFfP",
    "outputId": "fe8baf58-9cb2-4d80-e6e4-bbc53bd0ffb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "90000/90000 [==============================] - 36s 405us/step - loss: 0.6960 - acc: 0.5081 - val_loss: 0.6912 - val_acc: 0.5342\n",
      "roc-auc: 0.5349 - roc-auc_val: 0.5448                                                                                                    \n",
      "Epoch 2/50\n",
      "90000/90000 [==============================] - 35s 388us/step - loss: 0.6910 - acc: 0.5296 - val_loss: 0.6902 - val_acc: 0.5314\n",
      "roc-auc: 0.5563 - roc-auc_val: 0.5544                                                                                                    \n",
      "Epoch 3/50\n",
      "90000/90000 [==============================] - 35s 385us/step - loss: 0.6897 - acc: 0.5322 - val_loss: 0.6916 - val_acc: 0.5197\n",
      "roc-auc: 0.5578 - roc-auc_val: 0.5513                                                                                                    \n",
      "Epoch 4/50\n",
      "90000/90000 [==============================] - 35s 387us/step - loss: 0.6887 - acc: 0.5415 - val_loss: 0.6891 - val_acc: 0.5366\n",
      "roc-auc: 0.5653 - roc-auc_val: 0.5602                                                                                                    \n",
      "Epoch 5/50\n",
      "90000/90000 [==============================] - 35s 387us/step - loss: 0.6878 - acc: 0.5393 - val_loss: 0.6865 - val_acc: 0.5466\n",
      "roc-auc: 0.5702 - roc-auc_val: 0.5674                                                                                                    \n",
      "Epoch 6/50\n",
      "90000/90000 [==============================] - 34s 381us/step - loss: 0.6874 - acc: 0.5426 - val_loss: 0.6864 - val_acc: 0.5475\n",
      "roc-auc: 0.5745 - roc-auc_val: 0.5676                                                                                                    \n",
      "Epoch 7/50\n",
      "90000/90000 [==============================] - 34s 382us/step - loss: 0.6867 - acc: 0.5442 - val_loss: 0.6880 - val_acc: 0.5388\n",
      "roc-auc: 0.576 - roc-auc_val: 0.5674                                                                                                    \n",
      "Epoch 8/50\n",
      "90000/90000 [==============================] - 34s 382us/step - loss: 0.6863 - acc: 0.5441 - val_loss: 0.6858 - val_acc: 0.5534\n",
      "roc-auc: 0.5799 - roc-auc_val: 0.5698                                                                                                    \n",
      "Epoch 9/50\n",
      "90000/90000 [==============================] - 34s 383us/step - loss: 0.6859 - acc: 0.5457 - val_loss: 0.6878 - val_acc: 0.5332\n",
      "roc-auc: 0.5774 - roc-auc_val: 0.5715                                                                                                    \n",
      "Epoch 10/50\n",
      "90000/90000 [==============================] - 35s 386us/step - loss: 0.6849 - acc: 0.5493 - val_loss: 0.6853 - val_acc: 0.5482\n",
      "roc-auc: 0.5867 - roc-auc_val: 0.5726                                                                                                    \n",
      "Epoch 11/50\n",
      "90000/90000 [==============================] - 35s 389us/step - loss: 0.6845 - acc: 0.5508 - val_loss: 0.6859 - val_acc: 0.5446\n",
      "roc-auc: 0.585 - roc-auc_val: 0.5689                                                                                                    \n",
      "Epoch 12/50\n",
      "90000/90000 [==============================] - 35s 385us/step - loss: 0.6841 - acc: 0.5515 - val_loss: 0.6861 - val_acc: 0.5512\n",
      "roc-auc: 0.5885 - roc-auc_val: 0.5742                                                                                                    \n",
      "Epoch 13/50\n",
      "90000/90000 [==============================] - 35s 385us/step - loss: 0.6839 - acc: 0.5531 - val_loss: 0.6854 - val_acc: 0.5549\n",
      "roc-auc: 0.5896 - roc-auc_val: 0.5786                                                                                                    \n",
      "Epoch 14/50\n",
      "90000/90000 [==============================] - 35s 386us/step - loss: 0.6829 - acc: 0.5546 - val_loss: 0.6846 - val_acc: 0.5521\n",
      "roc-auc: 0.5921 - roc-auc_val: 0.5737                                                                                                    \n",
      "Epoch 15/50\n",
      "90000/90000 [==============================] - 34s 382us/step - loss: 0.6831 - acc: 0.5532 - val_loss: 0.6860 - val_acc: 0.5501\n",
      "roc-auc: 0.5925 - roc-auc_val: 0.5743                                                                                                    \n",
      "Epoch 16/50\n",
      "90000/90000 [==============================] - 35s 386us/step - loss: 0.6824 - acc: 0.5537 - val_loss: 0.6849 - val_acc: 0.5501\n",
      "roc-auc: 0.5972 - roc-auc_val: 0.5764                                                                                                    \n",
      "Epoch 17/50\n",
      "90000/90000 [==============================] - 34s 379us/step - loss: 0.6821 - acc: 0.5557 - val_loss: 0.6845 - val_acc: 0.5566\n",
      "roc-auc: 0.5996 - roc-auc_val: 0.5763                                                                                                    \n",
      "Epoch 18/50\n",
      "90000/90000 [==============================] - 34s 381us/step - loss: 0.6816 - acc: 0.5571 - val_loss: 0.6832 - val_acc: 0.5566\n",
      "roc-auc: 0.6015 - roc-auc_val: 0.5816                                                                                                    \n",
      "Epoch 19/50\n",
      "90000/90000 [==============================] - 34s 382us/step - loss: 0.6805 - acc: 0.5600 - val_loss: 0.6844 - val_acc: 0.5550\n",
      "roc-auc: 0.6029 - roc-auc_val: 0.5773                                                                                                    \n",
      "Epoch 20/50\n",
      "90000/90000 [==============================] - 34s 379us/step - loss: 0.6806 - acc: 0.5609 - val_loss: 0.6841 - val_acc: 0.5556\n",
      "roc-auc: 0.6017 - roc-auc_val: 0.579                                                                                                    \n",
      "Epoch 21/50\n",
      "90000/90000 [==============================] - 34s 381us/step - loss: 0.6809 - acc: 0.5596 - val_loss: 0.6839 - val_acc: 0.5569\n",
      "roc-auc: 0.6041 - roc-auc_val: 0.5806                                                                                                    \n",
      "Epoch 22/50\n",
      "90000/90000 [==============================] - 35s 385us/step - loss: 0.6798 - acc: 0.5616 - val_loss: 0.6842 - val_acc: 0.5641\n",
      "roc-auc: 0.6075 - roc-auc_val: 0.5805                                                                                                    \n",
      "Epoch 23/50\n",
      "90000/90000 [==============================] - 35s 385us/step - loss: 0.6797 - acc: 0.5621 - val_loss: 0.6831 - val_acc: 0.5598\n",
      "roc-auc: 0.6064 - roc-auc_val: 0.5795                                                                                                    \n",
      "Epoch 24/50\n",
      "90000/90000 [==============================] - 35s 386us/step - loss: 0.6798 - acc: 0.5614 - val_loss: 0.6843 - val_acc: 0.5579\n",
      "roc-auc: 0.6101 - roc-auc_val: 0.5798                                                                                                    \n",
      "Epoch 25/50\n",
      "90000/90000 [==============================] - 35s 383us/step - loss: 0.6784 - acc: 0.5654 - val_loss: 0.6835 - val_acc: 0.5625\n",
      "roc-auc: 0.6111 - roc-auc_val: 0.5835                                                                                                    \n",
      "Epoch 26/50\n",
      "90000/90000 [==============================] - 35s 389us/step - loss: 0.6785 - acc: 0.5641 - val_loss: 0.6829 - val_acc: 0.5592\n",
      "roc-auc: 0.6096 - roc-auc_val: 0.5846                                                                                                    \n",
      "Epoch 27/50\n",
      "90000/90000 [==============================] - 34s 380us/step - loss: 0.6780 - acc: 0.5675 - val_loss: 0.6856 - val_acc: 0.5511\n",
      "roc-auc: 0.6082 - roc-auc_val: 0.5809                                                                                                    \n",
      "Epoch 28/50\n",
      "90000/90000 [==============================] - 34s 382us/step - loss: 0.6780 - acc: 0.5664 - val_loss: 0.6874 - val_acc: 0.5616\n",
      "roc-auc: 0.6121 - roc-auc_val: 0.5865                                                                                                    \n",
      "Epoch 29/50\n",
      "90000/90000 [==============================] - 35s 385us/step - loss: 0.6763 - acc: 0.5681 - val_loss: 0.6844 - val_acc: 0.5462\n",
      "roc-auc: 0.6163 - roc-auc_val: 0.5851                                                                                                    \n",
      "Epoch 30/50\n",
      "90000/90000 [==============================] - 35s 388us/step - loss: 0.6757 - acc: 0.5696 - val_loss: 0.6834 - val_acc: 0.5691\n",
      "roc-auc: 0.6205 - roc-auc_val: 0.5882                                                                                                    \n",
      "Epoch 31/50\n",
      "90000/90000 [==============================] - 34s 383us/step - loss: 0.6760 - acc: 0.5706 - val_loss: 0.6850 - val_acc: 0.5554\n",
      "roc-auc: 0.6217 - roc-auc_val: 0.5886                                                                                                    \n",
      "Epoch 32/50\n",
      "90000/90000 [==============================] - 35s 385us/step - loss: 0.6745 - acc: 0.5722 - val_loss: 0.6852 - val_acc: 0.5603\n",
      "roc-auc: 0.6218 - roc-auc_val: 0.5876                                                                                                    \n",
      "Epoch 33/50\n",
      "90000/90000 [==============================] - 35s 385us/step - loss: 0.6749 - acc: 0.5703 - val_loss: 0.6833 - val_acc: 0.5635\n",
      "roc-auc: 0.6232 - roc-auc_val: 0.591                                                                                                    \n",
      "Epoch 34/50\n",
      "90000/90000 [==============================] - 34s 383us/step - loss: 0.6748 - acc: 0.5717 - val_loss: 0.6864 - val_acc: 0.5578\n",
      "roc-auc: 0.6207 - roc-auc_val: 0.5835                                                                                                    \n",
      "Epoch 35/50\n",
      "90000/90000 [==============================] - 34s 383us/step - loss: 0.6741 - acc: 0.5739 - val_loss: 0.6821 - val_acc: 0.5648\n",
      "roc-auc: 0.6221 - roc-auc_val: 0.5892                                                                                                    \n",
      "Epoch 36/50\n",
      "90000/90000 [==============================] - 35s 385us/step - loss: 0.6744 - acc: 0.5733 - val_loss: 0.6827 - val_acc: 0.5629\n",
      "roc-auc: 0.6234 - roc-auc_val: 0.5931                                                                                                    \n",
      "Epoch 37/50\n",
      "90000/90000 [==============================] - 35s 393us/step - loss: 0.6738 - acc: 0.5750 - val_loss: 0.6799 - val_acc: 0.5715\n",
      "roc-auc: 0.6269 - roc-auc_val: 0.5962                                                                                                    \n",
      "Epoch 38/50\n",
      "90000/90000 [==============================] - 35s 392us/step - loss: 0.6732 - acc: 0.5762 - val_loss: 0.6864 - val_acc: 0.5569\n",
      "roc-auc: 0.6262 - roc-auc_val: 0.5937                                                                                                    \n",
      "Epoch 39/50\n",
      "90000/90000 [==============================] - 37s 413us/step - loss: 0.6732 - acc: 0.5751 - val_loss: 0.6840 - val_acc: 0.5680\n",
      "roc-auc: 0.6322 - roc-auc_val: 0.5973                                                                                                    \n",
      "Epoch 40/50\n",
      "90000/90000 [==============================] - 35s 394us/step - loss: 0.6724 - acc: 0.5781 - val_loss: 0.6800 - val_acc: 0.5707\n",
      "roc-auc: 0.6286 - roc-auc_val: 0.5958                                                                                                    \n",
      "Epoch 41/50\n",
      "90000/90000 [==============================] - 34s 376us/step - loss: 0.6720 - acc: 0.5775 - val_loss: 0.6828 - val_acc: 0.5660\n",
      "roc-auc: 0.633 - roc-auc_val: 0.5934                                                                                                    \n",
      "Epoch 42/50\n",
      "90000/90000 [==============================] - 34s 377us/step - loss: 0.6721 - acc: 0.5779 - val_loss: 0.6851 - val_acc: 0.5682\n",
      "roc-auc: 0.6312 - roc-auc_val: 0.5924                                                                                                    \n",
      "Epoch 43/50\n",
      "30976/90000 [=========>....................] - ETA: 22s - loss: 0.6708 - acc: 0.5795"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=64,shuffle=True, \n",
    "          callbacks=[roc_callback(training_data=(X_train, y_train),validation_data=(X_test, y_test))])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "AmEx.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
